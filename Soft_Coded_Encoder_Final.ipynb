{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zadkel/Complex-transformer/blob/main/Soft_Coded_Encoder_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKa95RfFyC5s"
      },
      "outputs": [],
      "source": [
        "def zrelu(z): #z : tensor 활성화 함수 1\n",
        "\n",
        "    imag_relu = nn.relu(tf.math.imag(z))\n",
        "    real_relu = nn.relu(tf.math.real(z))\n",
        "    ret_real = imag_relu*real_relu / (imag_relu)\n",
        "    ret_imag = imag_relu*real_relu / (real_relu)\n",
        "    return ret_real + 1j*ret_imag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fV-org8AzOrQ"
      },
      "outputs": [],
      "source": [
        "def modrelu(z: Tensor, b: float = 1) : #활성화 함수 2\n",
        "      return nn.relu(abs(z) + b) * z / abs(z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PAPL37fDz6QW"
      },
      "outputs": [],
      "source": [
        "def cardioid(z): #활성화 함수 3\n",
        "  return (1+math.cos(torch.angle(z))) * z / 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJNCIHvy2PSZ"
      },
      "outputs": [],
      "source": [
        "def complexMSE():"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WVujhRP1eTq",
        "outputId": "57224b9a-965f-4248-a39b-35bb4c711553"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/100], Loss: 0.7357\n",
            "Epoch [2/100], Loss: 0.7371\n",
            "Epoch [3/100], Loss: 0.7270\n",
            "Epoch [4/100], Loss: 0.7334\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "'''\n",
        "[24/06/19 patch note]\n",
        "- Adding 'PositionalEncoding' Class\n",
        "- Modifying 'PositionWiseFeedForward' method\n",
        "\n",
        "[24/06/21 patch note]\n",
        "- Adding 'ComplexLinear' Class\n",
        "- Modifying nn.Linear to ComplexLinear\n",
        "'''\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from copy import deepcopy\n",
        "import math\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.nn.parameter import Parameter, UninitializedParameter\n",
        "from torch import Tensor\n",
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "class ComplexLinear(nn.Module):\n",
        "\n",
        "    __constants__ = ['in_features', 'out_features']\n",
        "    in_features: int\n",
        "    out_features: int\n",
        "    real_weight: Tensor\n",
        "    imag_weight: Tensor\n",
        "\n",
        "    def __init__(self, in_features: int, out_features: int, bias: bool = True,\n",
        "                 device=None, dtype=None) -> None:\n",
        "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
        "        super().__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.real_weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))\n",
        "        self.imag_weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))\n",
        "        if bias:\n",
        "            self.real_bias = Parameter(torch.empty(out_features, **factory_kwargs))\n",
        "            self.imag_bias = Parameter(torch.empty(out_features, **factory_kwargs))\n",
        "        else:\n",
        "            self.register_parameter('real_bias', None)\n",
        "            self.register_parameter('imag_bias', None)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self) -> None:\n",
        "        nn.init.kaiming_uniform_(self.real_weight, a=math.sqrt(5))\n",
        "        nn.init.kaiming_uniform_(self.imag_weight, a=math.sqrt(5))\n",
        "        if self.real_bias is not None:\n",
        "            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.real_weight)\n",
        "            bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n",
        "            nn.init.uniform_(self.real_bias, -bound, bound)\n",
        "            nn.init.uniform_(self.imag_bias, -bound, bound)\n",
        "\n",
        "    def forward(self, input: Tensor) -> Tensor:\n",
        "        input_real = input.real\n",
        "        input_imag = input.imag\n",
        "\n",
        "        real_output = torch.matmul(input_real, self.real_weight.T) - torch.matmul(input_imag, self.imag_weight.T)\n",
        "        imag_output = torch.matmul(input_real, self.imag_weight.T) + torch.matmul(input_imag, self.real_weight.T)\n",
        "\n",
        "        if self.real_bias is not None:\n",
        "            real_output += self.real_bias\n",
        "            imag_output += self.imag_bias\n",
        "\n",
        "        return torch.complex(real_output, imag_output)\n",
        "\n",
        "    def extra_repr(self) -> str:\n",
        "        return f'in_features={self.in_features}, out_features={self.out_features}, bias={self.real_bias is not None}'\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self, encoder_block, n_layer):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.layers = nn.ModuleList([deepcopy(encoder_block) for _ in range(n_layer)])\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "        out = src\n",
        "        for layer in self.layers:\n",
        "            out = layer(out, src_mask)\n",
        "        return out\n",
        "\n",
        "class EncoderBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, self_attention, position_ff):\n",
        "        super(EncoderBlock, self).__init__()\n",
        "        self.self_attention = self_attention\n",
        "        self.position_ff = position_ff\n",
        "        self.residuals = nn.ModuleList([ResidualConnectionLayer() for _ in range(2)])\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "        out = src\n",
        "        out = self.residuals[0](out, lambda out: self.self_attention(query=out, key=out, value=out, mask=src_mask))\n",
        "        out = self.residuals[1](out, self.position_ff)\n",
        "        return out\n",
        "\n",
        "class ResidualConnectionLayer(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(ResidualConnectionLayer, self).__init__()\n",
        "\n",
        "    def forward(self, x, sub_layer):\n",
        "        out = x\n",
        "        out = sub_layer(out)\n",
        "        out = out + x\n",
        "        return x\n",
        "\n",
        "class MultiHeadAttentionLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, h, qkv_fc, out_fc):\n",
        "        super(MultiHeadAttentionLayer, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.h = h\n",
        "        self.q_fc = deepcopy(qkv_fc)\n",
        "        self.k_fc = deepcopy(qkv_fc)\n",
        "        self.v_fc = deepcopy(qkv_fc)\n",
        "        self.out_fc = out_fc\n",
        "\n",
        "    def forward(self, query, key, value, mask=None):\n",
        "        n_batch = query.size(0)\n",
        "\n",
        "        def transform(x, fc):\n",
        "            out = fc(x)\n",
        "            out = out.view(n_batch, -1, self.h, self.d_model // self.h)\n",
        "            out = out.transpose(1, 2)\n",
        "            return out\n",
        "\n",
        "        query = transform(query, self.q_fc)\n",
        "        key = transform(key, self.k_fc)\n",
        "        value = transform(value, self.v_fc)\n",
        "\n",
        "        out = self.calculate_attention(query, key, value, mask)\n",
        "        out = out.transpose(1, 2)\n",
        "        out = out.contiguous().view(n_batch, -1, self.d_model)\n",
        "        out = self.out_fc(out)\n",
        "        return out\n",
        "\n",
        "    def calculate_attention(self, query, key, value, mask):\n",
        "        d_k = key.shape[-1]\n",
        "        attention_score = torch.matmul(query, key.transpose(-2, -1))\n",
        "        attention_score = attention_score / math.sqrt(d_k)\n",
        "\n",
        "        # attention_score = attention_score.masked_fill(mask == 0, -1e9)\n",
        "\n",
        "        attention_prob = F.softmax(abs(attention_score), dim=-1)\n",
        "        out = torch.matmul(attention_prob, value.real) + 1j * torch.matmul(attention_prob, value.imag)\n",
        "        # attention_prob = F.softmax(attention_score, dim=-1)\n",
        "        # out = torch.matmul(attention_prob, value)\n",
        "        return out\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_embed = 512, max_len = 256, device = torch.device(\"cpu\")):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        encoding = torch.zeros(max_len, d_embed)\n",
        "        encoding_requires_grad = False\n",
        "        position = torch.arange(0, max_len).float().unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_embed, 2) *  -(math.log(10000.0) / d_embed))\n",
        "        encoding[:, :] = torch.exp(1j* position * div_term)\n",
        "        self. encoding = encoding.unsqueeze(0).to(device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, seq_len, _ = x.size()\n",
        "        pos_embed = self.encoding[:, :seq_len, :]\n",
        "        out = x + pos_embed\n",
        "        return out\n",
        "\n",
        "class PositionWiseFeedForwardLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, fc1, fc2):\n",
        "        super(PositionWiseFeedForwardLayer, self).__init__()\n",
        "        self.fc1 = fc1 # (d_embed, d_ff)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = fc2 # (d_ff, d_embed)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = x\n",
        "        out = self.fc1(out)\n",
        "        out = self.zrelu(out)\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "\n",
        "    def zrelu(self, z): #z : tensor 활성화 함수 1\n",
        "        real_parts = z.real\n",
        "        imag_parts = z.imag\n",
        "\n",
        "        mask = (real_parts > 0) & (imag_parts > 0)\n",
        "\n",
        "        filtered_tensor = torch.where(mask, z, torch.zeros_like(z))\n",
        "\n",
        "        return filtered_tensor\n",
        "\n",
        "### Hyperparameter ###\n",
        "d_embed = 512\n",
        "d_model = 512\n",
        "h = 8\n",
        "d_ff = 2048\n",
        "n_layer = 6\n",
        "batch_size = 64\n",
        "num_epochs = 100\n",
        "\n",
        "attention = MultiHeadAttentionLayer(d_model = d_model, h = h, qkv_fc = ComplexLinear(d_embed, d_model), out_fc = ComplexLinear(d_model, d_embed))\n",
        "position_ff = PositionWiseFeedForwardLayer(fc1 = ComplexLinear(d_embed, d_ff), fc2 = ComplexLinear(d_ff, d_embed))\n",
        "\n",
        "encoder_block = EncoderBlock(self_attention = attention, position_ff = position_ff)\n",
        "\n",
        "model = Encoder(encoder_block, n_layer)\n",
        "\n",
        "x_train = torch.complex(torch.rand(8551,45,512),torch.rand(8551,45,512))\n",
        "y_train = torch.randint(0, 2, (8551,)).float()\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "dataset = TensorDataset(x_train, y_train)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch_x, batch_y in dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        src_mask = None  # Assuming no mask for simplicity\n",
        "        output = model(batch_x, src_mask)\n",
        "        output = output.mean(dim=1)\n",
        "        output = ComplexLinear(d_model, 1)(output)\n",
        "        output = abs(output)\n",
        "        output = torch.sigmoid(output)  # Apply sigmoid for binary classification\n",
        "        output = output.squeeze(-1)\n",
        "\n",
        "        loss = criterion(output, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
        "\n",
        "print(\"Training complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVBBk9whIVP6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from copy import deepcopy\n",
        "import math\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qa6a2hn1IfJX"
      },
      "outputs": [],
      "source": [
        "a = torch.rand(3,2)\n",
        "b = torch.rand(2,3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTCalT0rLN1v"
      },
      "outputs": [],
      "source": [
        "c = torch.view_as_complex(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmcmC6KTLPV8",
        "outputId": "24abd062-6e31-40cc-b82a-1f00ca0f1b69"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<function Tensor.type>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "c.type"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}